{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "db1b8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6dabcb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>saldo</th>\n",
       "      <th>duracion</th>\n",
       "      <th>campa√±a</th>\n",
       "      <th>pdias</th>\n",
       "      <th>anterior</th>\n",
       "      <th>trabajo_0</th>\n",
       "      <th>trabajo_1</th>\n",
       "      <th>trabajo_2</th>\n",
       "      <th>trabajo_3</th>\n",
       "      <th>...</th>\n",
       "      <th>mes_7</th>\n",
       "      <th>mes_8</th>\n",
       "      <th>mes_9</th>\n",
       "      <th>mes_10</th>\n",
       "      <th>mes_11</th>\n",
       "      <th>presultado_0</th>\n",
       "      <th>presultado_1</th>\n",
       "      <th>presultado_2</th>\n",
       "      <th>presultado_3</th>\n",
       "      <th>dep_a_plazo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016769</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.044159</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.996434</td>\n",
       "      <td>0.045775</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.070535</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024956</td>\n",
       "      <td>0.962605</td>\n",
       "      <td>0.131912</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.235303</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020139</td>\n",
       "      <td>0.990829</td>\n",
       "      <td>0.133587</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.252592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967554</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>-0.004281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>0.080210</td>\n",
       "      <td>0.736741</td>\n",
       "      <td>0.671385</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>0.033947</td>\n",
       "      <td>-0.632870</td>\n",
       "      <td>0.773508</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>0.068663</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>0.195816</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>0.036535</td>\n",
       "      <td>0.291064</td>\n",
       "      <td>0.956004</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>0.012473</td>\n",
       "      <td>0.965895</td>\n",
       "      <td>0.258624</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6021 rows √ó 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          edad     saldo  duracion   campa√±a     pdias  anterior  trabajo_0  \\\n",
       "0     0.016769  0.998883  0.044159  0.000559 -0.000559  0.000000        0.0   \n",
       "1     0.006866  0.996434  0.045775  0.000208  0.070535  0.000832        0.0   \n",
       "2     0.024956  0.962605  0.131912  0.000713  0.235303  0.000713        0.0   \n",
       "3     0.020139  0.990829  0.133587  0.002685 -0.000671  0.000000        0.0   \n",
       "4     0.252592  0.000000  0.967554  0.004281 -0.004281  0.000000        0.0   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "6016  0.080210  0.736741  0.671385  0.004456 -0.001485  0.000000        0.0   \n",
       "6017  0.033947 -0.632870  0.773508  0.002425 -0.001212  0.000000        0.0   \n",
       "6018  0.068663  0.978233  0.195816  0.000848 -0.000848  0.000000        0.0   \n",
       "6019  0.036535  0.291064  0.956004  0.001218 -0.001218  0.000000        0.0   \n",
       "6020  0.012473  0.965895  0.258624  0.002201 -0.000367  0.000000        0.0   \n",
       "\n",
       "      trabajo_1  trabajo_2  trabajo_3  ...  mes_7  mes_8  mes_9  mes_10  \\\n",
       "0           0.0        0.0        0.0  ...    0.0    0.0    0.0     1.0   \n",
       "1           0.0        0.0        0.0  ...    0.0    1.0    0.0     0.0   \n",
       "2           0.0        0.0        0.0  ...    0.0    0.0    0.0     0.0   \n",
       "3           0.0        0.0        0.0  ...    0.0    0.0    0.0     0.0   \n",
       "4           1.0        0.0        0.0  ...    0.0    1.0    0.0     0.0   \n",
       "...         ...        ...        ...  ...    ...    ...    ...     ...   \n",
       "6016        0.0        0.0        0.0  ...    0.0    0.0    0.0     0.0   \n",
       "6017        0.0        0.0        0.0  ...    0.0    1.0    0.0     0.0   \n",
       "6018        0.0        0.0        0.0  ...    0.0    0.0    0.0     0.0   \n",
       "6019        1.0        0.0        0.0  ...    0.0    1.0    0.0     0.0   \n",
       "6020        0.0        0.0        0.0  ...    0.0    0.0    1.0     0.0   \n",
       "\n",
       "      mes_11  presultado_0  presultado_1  presultado_2  presultado_3  \\\n",
       "0        0.0           0.0           0.0           0.0           1.0   \n",
       "1        0.0           1.0           0.0           0.0           0.0   \n",
       "2        0.0           1.0           0.0           0.0           0.0   \n",
       "3        0.0           0.0           0.0           0.0           1.0   \n",
       "4        0.0           0.0           0.0           0.0           1.0   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "6016     0.0           0.0           0.0           0.0           1.0   \n",
       "6017     0.0           0.0           0.0           0.0           1.0   \n",
       "6018     1.0           0.0           0.0           0.0           1.0   \n",
       "6019     0.0           0.0           0.0           0.0           1.0   \n",
       "6020     0.0           0.0           0.0           0.0           1.0   \n",
       "\n",
       "      dep_a_plazo  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "6016            1  \n",
       "6017            1  \n",
       "6018            1  \n",
       "6019            1  \n",
       "6020            1  \n",
       "\n",
       "[6021 rows x 51 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('datos_procesados.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "93eb1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(units=100, activation='relu',input_shape=(50,)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate=0.7))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7ffab9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['Recall', 'Precision', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "30d763c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,601\n",
      "Trainable params: 5,401\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c7643122",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns='dep_a_plazo')\n",
    "y=df.dep_a_plazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "56f0cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y, stratify=y, test_size=0.33)\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "y_train=y_train.reshape(len(y_train),1)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)\n",
    "y_test=y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "35193dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "135/135 [==============================] - 33s 10ms/step - loss: 0.8656 - recall: 0.5244 - precision: 0.4257 - auc: 0.6155\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.6732 - recall: 0.5118 - precision: 0.5254 - auc: 0.6927\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.5762 - recall: 0.5103 - precision: 0.5881 - auc: 0.7426\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.5496 - recall: 0.4867 - precision: 0.6270 - auc: 0.7578\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.5259 - recall: 0.5118 - precision: 0.6532 - auc: 0.7772\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.5085 - recall: 0.5111 - precision: 0.6647 - auc: 0.7913\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4884 - recall: 0.5310 - precision: 0.6815 - auc: 0.8081\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4853 - recall: 0.5421 - precision: 0.6977 - auc: 0.8136\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4859 - recall: 0.5458 - precision: 0.6939 - auc: 0.8148\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4751 - recall: 0.5480 - precision: 0.7047 - auc: 0.8210\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4642 - recall: 0.5746 - precision: 0.7112 - auc: 0.8349\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4634 - recall: 0.5783 - precision: 0.7073 - auc: 0.8373\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4589 - recall: 0.5739 - precision: 0.7096 - auc: 0.8402\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4502 - recall: 0.5820 - precision: 0.7190 - auc: 0.8482\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.4485 - recall: 0.5775 - precision: 0.7201 - auc: 0.8476\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4525 - recall: 0.5835 - precision: 0.7288 - auc: 0.8477\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4450 - recall: 0.6137 - precision: 0.7232 - auc: 0.8515\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4350 - recall: 0.5960 - precision: 0.7186 - auc: 0.8598\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4328 - recall: 0.6123 - precision: 0.7209 - auc: 0.8608\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.4358 - recall: 0.6152 - precision: 0.7294 - auc: 0.8589\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4243 - recall: 0.6108 - precision: 0.7377 - auc: 0.8662\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.4446 - recall: 0.6034 - precision: 0.7314 - auc: 0.8536\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4339 - recall: 0.6108 - precision: 0.7410 - auc: 0.8612\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4232 - recall: 0.6189 - precision: 0.7344 - auc: 0.8703\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4308 - recall: 0.6352 - precision: 0.7301 - auc: 0.8628\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.4227 - recall: 0.6219 - precision: 0.7498 - auc: 0.8705\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4257 - recall: 0.6359 - precision: 0.7467 - auc: 0.8677\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4169 - recall: 0.6433 - precision: 0.7425 - auc: 0.8730\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.4208 - recall: 0.6189 - precision: 0.7268 - auc: 0.8692\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.4150 - recall: 0.6462 - precision: 0.7491 - auc: 0.8753\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.4114 - recall: 0.6455 - precision: 0.7401 - auc: 0.8757\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4163 - recall: 0.6440 - precision: 0.7409 - auc: 0.8728\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4163 - recall: 0.6440 - precision: 0.7352 - auc: 0.8730\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.4149 - recall: 0.6470 - precision: 0.7318 - auc: 0.8743\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4101 - recall: 0.6610 - precision: 0.7471 - auc: 0.8776\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4115 - recall: 0.6544 - precision: 0.7470 - auc: 0.8773\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4055 - recall: 0.6492 - precision: 0.7468 - auc: 0.8811\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3954 - recall: 0.6640 - precision: 0.7504 - auc: 0.8854\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4081 - recall: 0.6529 - precision: 0.7517 - auc: 0.8793\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.4048 - recall: 0.6728 - precision: 0.7443 - auc: 0.8815\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4094 - recall: 0.6558 - precision: 0.7506 - auc: 0.8780\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3998 - recall: 0.6713 - precision: 0.7451 - auc: 0.8854\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 2s 18ms/step - loss: 0.4158 - recall: 0.6462 - precision: 0.7460 - auc: 0.8746\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.4052 - recall: 0.6536 - precision: 0.7584 - auc: 0.8818\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.4026 - recall: 0.6603 - precision: 0.7401 - auc: 0.8822\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.3835 - recall: 0.6706 - precision: 0.7688 - auc: 0.8956\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3891 - recall: 0.6787 - precision: 0.7558 - auc: 0.8905\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3946 - recall: 0.6699 - precision: 0.7654 - auc: 0.8897\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3998 - recall: 0.6750 - precision: 0.7413 - auc: 0.8854\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3957 - recall: 0.6802 - precision: 0.7568 - auc: 0.8880\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.4063 - recall: 0.6581 - precision: 0.7437 - auc: 0.8800\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.4005 - recall: 0.6654 - precision: 0.7688 - auc: 0.8849\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3914 - recall: 0.6824 - precision: 0.7568 - auc: 0.8895\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3932 - recall: 0.6677 - precision: 0.7687 - auc: 0.8886\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3890 - recall: 0.6809 - precision: 0.7502 - auc: 0.8915\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3902 - recall: 0.6758 - precision: 0.7512 - auc: 0.8914\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3882 - recall: 0.6773 - precision: 0.7566 - auc: 0.8926\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3800 - recall: 0.6861 - precision: 0.7703 - auc: 0.8969\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 0.3961 - recall: 0.6558 - precision: 0.7551 - auc: 0.8879\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3832 - recall: 0.6795 - precision: 0.7610 - auc: 0.8954\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3911 - recall: 0.6684 - precision: 0.7523 - auc: 0.8899\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3786 - recall: 0.6987 - precision: 0.7514 - auc: 0.8964\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3967 - recall: 0.6617 - precision: 0.7613 - auc: 0.8880\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3832 - recall: 0.6928 - precision: 0.7632 - auc: 0.8940\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3837 - recall: 0.6765 - precision: 0.7490 - auc: 0.8945\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3862 - recall: 0.6773 - precision: 0.7654 - auc: 0.8945\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3852 - recall: 0.6883 - precision: 0.7596 - auc: 0.8927\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3881 - recall: 0.6758 - precision: 0.7562 - auc: 0.8927\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3796 - recall: 0.6883 - precision: 0.7646 - auc: 0.8969\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3769 - recall: 0.7038 - precision: 0.7630 - auc: 0.8991\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3768 - recall: 0.6994 - precision: 0.7643 - auc: 0.8988\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3808 - recall: 0.6765 - precision: 0.7704 - auc: 0.8960\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.3772 - recall: 0.7031 - precision: 0.7709 - auc: 0.8990\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 0.3774 - recall: 0.6861 - precision: 0.7684 - auc: 0.8991\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3778 - recall: 0.6883 - precision: 0.7793 - auc: 0.8985\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3802 - recall: 0.6817 - precision: 0.7796 - auc: 0.8971\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3861 - recall: 0.6787 - precision: 0.7490 - auc: 0.8936\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3787 - recall: 0.6913 - precision: 0.7666 - auc: 0.8977\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3811 - recall: 0.6883 - precision: 0.7709 - auc: 0.8970\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3821 - recall: 0.6898 - precision: 0.7656 - auc: 0.8952\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3700 - recall: 0.6950 - precision: 0.7713 - auc: 0.9014\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 0.3689 - recall: 0.6920 - precision: 0.7744 - auc: 0.9035\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3785 - recall: 0.6905 - precision: 0.7664 - auc: 0.8971\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3824 - recall: 0.6883 - precision: 0.7627 - auc: 0.8955\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.3799 - recall: 0.6869 - precision: 0.7635 - auc: 0.8972\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.3714 - recall: 0.6898 - precision: 0.7681 - auc: 0.9019\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3691 - recall: 0.6965 - precision: 0.7819 - auc: 0.9027\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3741 - recall: 0.6935 - precision: 0.7709 - auc: 0.9005\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3744 - recall: 0.6824 - precision: 0.7804 - auc: 0.9002\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3787 - recall: 0.6935 - precision: 0.7634 - auc: 0.8976\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3738 - recall: 0.7009 - precision: 0.7550 - auc: 0.9002\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3746 - recall: 0.6957 - precision: 0.7747 - auc: 0.8991\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3784 - recall: 0.6972 - precision: 0.7719 - auc: 0.8983\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3613 - recall: 0.7171 - precision: 0.7869 - auc: 0.9075\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3754 - recall: 0.6750 - precision: 0.7779 - auc: 0.9000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3676 - recall: 0.7001 - precision: 0.7739 - auc: 0.9035\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3701 - recall: 0.7105 - precision: 0.7721 - auc: 0.9038\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3597 - recall: 0.6839 - precision: 0.7814 - auc: 0.9074\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3662 - recall: 0.7164 - precision: 0.7861 - auc: 0.9055\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3689 - recall: 0.7194 - precision: 0.7615 - auc: 0.9038\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3701 - recall: 0.6832 - precision: 0.7799 - auc: 0.9018\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3639 - recall: 0.7238 - precision: 0.7821 - auc: 0.9057\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3680 - recall: 0.6942 - precision: 0.7769 - auc: 0.9038\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3621 - recall: 0.7179 - precision: 0.7782 - auc: 0.9068\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3609 - recall: 0.7112 - precision: 0.7848 - auc: 0.9084\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3598 - recall: 0.7009 - precision: 0.7975 - auc: 0.9076\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3665 - recall: 0.7194 - precision: 0.7755 - auc: 0.9054\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3673 - recall: 0.7157 - precision: 0.7802 - auc: 0.9055\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3638 - recall: 0.7097 - precision: 0.7975 - auc: 0.9082\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3622 - recall: 0.7068 - precision: 0.7812 - auc: 0.9062\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3678 - recall: 0.6994 - precision: 0.7769 - auc: 0.9041\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3702 - recall: 0.7097 - precision: 0.7813 - auc: 0.9034\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3671 - recall: 0.7053 - precision: 0.7821 - auc: 0.9050\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3689 - recall: 0.7090 - precision: 0.7888 - auc: 0.9027\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3701 - recall: 0.7097 - precision: 0.7688 - auc: 0.9029\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3587 - recall: 0.7134 - precision: 0.7957 - auc: 0.9099\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3565 - recall: 0.7179 - precision: 0.7858 - auc: 0.9111\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3738 - recall: 0.7016 - precision: 0.7787 - auc: 0.9009\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3583 - recall: 0.7112 - precision: 0.7823 - auc: 0.9085\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3590 - recall: 0.7179 - precision: 0.7845 - auc: 0.9094\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3640 - recall: 0.7238 - precision: 0.7747 - auc: 0.9069\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3631 - recall: 0.7061 - precision: 0.7920 - auc: 0.9073\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3548 - recall: 0.7171 - precision: 0.7869 - auc: 0.9124\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3589 - recall: 0.7253 - precision: 0.7769 - auc: 0.9096\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3636 - recall: 0.7061 - precision: 0.7993 - auc: 0.9068\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3581 - recall: 0.7179 - precision: 0.7739 - auc: 0.9096\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3604 - recall: 0.7142 - precision: 0.7780 - auc: 0.9075\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.3512 - recall: 0.7208 - precision: 0.7929 - auc: 0.9131\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3574 - recall: 0.6965 - precision: 0.7931 - auc: 0.9094\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3587 - recall: 0.7171 - precision: 0.7756 - auc: 0.9076\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3557 - recall: 0.7090 - precision: 0.7895 - auc: 0.9122\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3642 - recall: 0.7112 - precision: 0.7766 - auc: 0.9067\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3575 - recall: 0.7083 - precision: 0.7893 - auc: 0.9098\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3653 - recall: 0.7068 - precision: 0.7800 - auc: 0.9058\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3616 - recall: 0.7097 - precision: 0.7832 - auc: 0.9069\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3626 - recall: 0.7149 - precision: 0.7889 - auc: 0.9069\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3560 - recall: 0.7157 - precision: 0.8022 - auc: 0.9113\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3643 - recall: 0.7216 - precision: 0.7615 - auc: 0.9056\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3546 - recall: 0.6920 - precision: 0.7921 - auc: 0.9101\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3561 - recall: 0.7038 - precision: 0.7857 - auc: 0.9099\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3557 - recall: 0.7090 - precision: 0.7742 - auc: 0.9100\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3639 - recall: 0.7075 - precision: 0.7820 - auc: 0.9055\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3580 - recall: 0.7149 - precision: 0.7683 - auc: 0.9085\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3500 - recall: 0.7105 - precision: 0.7879 - auc: 0.9134\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3539 - recall: 0.7157 - precision: 0.7802 - auc: 0.9104\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3524 - recall: 0.7134 - precision: 0.7918 - auc: 0.9112\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3575 - recall: 0.7171 - precision: 0.7743 - auc: 0.9103\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3703 - recall: 0.6876 - precision: 0.7837 - auc: 0.9017\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 0.3644 - recall: 0.7157 - precision: 0.7789 - auc: 0.9060\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3622 - recall: 0.7031 - precision: 0.7855 - auc: 0.9071\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3534 - recall: 0.7038 - precision: 0.7811 - auc: 0.9119\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3634 - recall: 0.7186 - precision: 0.7772 - auc: 0.9066\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3453 - recall: 0.7238 - precision: 0.7967 - auc: 0.9154\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3575 - recall: 0.7223 - precision: 0.7855 - auc: 0.9098\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3479 - recall: 0.7238 - precision: 0.8053 - auc: 0.9132\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3562 - recall: 0.7046 - precision: 0.8010 - auc: 0.9106\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3485 - recall: 0.7378 - precision: 0.7866 - auc: 0.9141\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3584 - recall: 0.7068 - precision: 0.8015 - auc: 0.9097\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3467 - recall: 0.7297 - precision: 0.8000 - auc: 0.9162\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3574 - recall: 0.7208 - precision: 0.7909 - auc: 0.9101\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3451 - recall: 0.7341 - precision: 0.7858 - auc: 0.9155\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3493 - recall: 0.7297 - precision: 0.8000 - auc: 0.9155\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3497 - recall: 0.7053 - precision: 0.7860 - auc: 0.9141\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3448 - recall: 0.7282 - precision: 0.7832 - auc: 0.9159\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3481 - recall: 0.7083 - precision: 0.7965 - auc: 0.9146\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3634 - recall: 0.7194 - precision: 0.7669 - auc: 0.9074\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3481 - recall: 0.7216 - precision: 0.7937 - auc: 0.9148\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3514 - recall: 0.7194 - precision: 0.7811 - auc: 0.9114\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3616 - recall: 0.7061 - precision: 0.7914 - auc: 0.9075\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3662 - recall: 0.6994 - precision: 0.7775 - auc: 0.9043\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3481 - recall: 0.7112 - precision: 0.7992 - auc: 0.9157\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3445 - recall: 0.7216 - precision: 0.7917 - auc: 0.9158\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3496 - recall: 0.7304 - precision: 0.7893 - auc: 0.9138\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3394 - recall: 0.7304 - precision: 0.8073 - auc: 0.9196\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3522 - recall: 0.7171 - precision: 0.7831 - auc: 0.9120\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3558 - recall: 0.7112 - precision: 0.7723 - auc: 0.9091\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3516 - recall: 0.7112 - precision: 0.7887 - auc: 0.9123\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3494 - recall: 0.7260 - precision: 0.7883 - auc: 0.9145\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3490 - recall: 0.7134 - precision: 0.7977 - auc: 0.9140\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3582 - recall: 0.7216 - precision: 0.7816 - auc: 0.9090\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3513 - recall: 0.7186 - precision: 0.7872 - auc: 0.9130\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3553 - recall: 0.7046 - precision: 0.7917 - auc: 0.9112\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3512 - recall: 0.7319 - precision: 0.7853 - auc: 0.9132\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3551 - recall: 0.7157 - precision: 0.7853 - auc: 0.9110\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3473 - recall: 0.7157 - precision: 0.7853 - auc: 0.9143\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3571 - recall: 0.7024 - precision: 0.7834 - auc: 0.9094\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3505 - recall: 0.7179 - precision: 0.7928 - auc: 0.9132\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3579 - recall: 0.7142 - precision: 0.7843 - auc: 0.9096\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3541 - recall: 0.7075 - precision: 0.7814 - auc: 0.9110\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3442 - recall: 0.7134 - precision: 0.7970 - auc: 0.9162\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3457 - recall: 0.7326 - precision: 0.7904 - auc: 0.9150\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.3532 - recall: 0.7267 - precision: 0.7797 - auc: 0.9118\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3575 - recall: 0.7194 - precision: 0.7880 - auc: 0.9108\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3466 - recall: 0.7134 - precision: 0.8043 - auc: 0.9157\n"
     ]
    }
   ],
   "source": [
    "stop=tf.keras.callbacks.EarlyStopping(monitor='loss',patience=20)\n",
    "history=model.fit(x_train, y_train, epochs=200, callbacks=[stop], batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "90ecfa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 8ms/step - loss: 0.3780 - recall: 0.7121 - precision: 0.7649 - auc: 0.9047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37796473503112793,\n",
       " 0.7121439576148987,\n",
       " 0.7648953199386597,\n",
       " 0.9047487378120422]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "81fcfd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1=y_train.reshape(len(y_train),)\n",
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f7b18bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "def evaluar_modelo_recall(estimador, X, y):\n",
    "    resultados_estimador = cross_validate(estimador, X, y,\n",
    "                     scoring='recall', cv=10, return_train_score=True)\n",
    "    return resultados_estimador\n",
    "def evaluar_modelo_roc(estimador, X, y):\n",
    "    resultados_estimador = cross_validate(estimador, X, y,\n",
    "                     scoring='roc_auc', cv=10, return_train_score=True)\n",
    "    return resultados_estimador\n",
    "def evaluar_modelo_pre(estimador, X, y):\n",
    "    resultados_estimador = cross_validate(estimador, X, y,\n",
    "                     scoring='precision', cv=10, return_train_score=True)\n",
    "    return resultados_estimador\n",
    "def promedios_cv(puntuacion):\n",
    "    for dato in puntuacion:\n",
    "        puntuacion[dato]=np.mean(puntuacion.get(dato))\n",
    "    return puntuacion\n",
    "\n",
    "puntuacion1=evaluar_modelo_recall(RandomForestClassifier(max_depth=5),x_train,y_train1)\n",
    "puntuacion1_a=evaluar_modelo_roc(RandomForestClassifier(max_depth=5),x_train,y_train1)\n",
    "puntuacion1_b=evaluar_modelo_pre(RandomForestClassifier(max_depth=5),x_train,y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "76b9ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores=pd.DataFrame(promedios_cv(puntuacion1), index=['RFC_recall'])\n",
    "Scores=pd.concat([Scores, pd.DataFrame(promedios_cv(puntuacion1_a), index=['RFC_roc'])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3361fc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFC_recall</th>\n",
       "      <td>1.196124</td>\n",
       "      <td>0.064599</td>\n",
       "      <td>0.389973</td>\n",
       "      <td>0.423682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC_roc</th>\n",
       "      <td>1.168364</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.863291</td>\n",
       "      <td>0.890543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC_pre</th>\n",
       "      <td>1.152789</td>\n",
       "      <td>0.060108</td>\n",
       "      <td>0.799852</td>\n",
       "      <td>0.849773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fit_time  score_time  test_score  train_score\n",
       "RFC_recall  1.196124    0.064599    0.389973     0.423682\n",
       "RFC_roc     1.168364    0.063902    0.863291     0.890543\n",
       "RFC_pre     1.152789    0.060108    0.799852     0.849773"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores1=pd.DataFrame(promedios_cv(puntuacion1_b), index=['RFC_pre'])\n",
    "Scores=pd.concat([Scores, Scores1], axis=0)\n",
    "Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e655198",
   "metadata": {},
   "source": [
    "#### Debido a que en este caso nos interesa bastante la puntuaci√≥n de recall (ya que no solo nos importa acertar cuando predecimos que un cliente pedir√° un dep√≥sito a plazo sino muy importante tambien, detectar la mayor cantidad de ellos que esto es lo que mide recall)\n",
    "recall $=\\frac{TP}{TP+FN}$ \n",
    "#### entonces la red neuronal tiene un mejor rendimiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7c279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
